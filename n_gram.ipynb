{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGN6OIGDyLVI1GoCicuHKt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/florianraith/notebooks/blob/main/n_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup kaggle and download dataset"
      ],
      "metadata": {
        "id": "W8j3SqkbgGq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vQKuAUgcWaR",
        "outputId": "5b9961be-cb29-4d12-badd-5d2393164f48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "MU6FrQ9oc_fg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp \"/content/drive/MyDrive/Sonstiges/kaggle.json\" ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ZCPmOfKvdDCu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/us-baby-names.zip'\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    !kaggle datasets download -d kaggle/us-baby-names\n",
        "    !unzip -o {dataset_path} -d /content/\n",
        "else:\n",
        "    print('Dataset already exists.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ywuJ3od7nB",
        "outputId": "7dab21ac-147a-4aad-fe1a-e876a675c076"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading us-baby-names.zip to /content\n",
            " 96% 166M/173M [00:03<00:00, 50.8MB/s]\n",
            "100% 173M/173M [00:03<00:00, 54.7MB/s]\n",
            "Archive:  /content/us-baby-names.zip\n",
            "  inflating: /content/NationalNames.csv  \n",
            "  inflating: /content/NationalReadMe.pdf  \n",
            "  inflating: /content/StateNames.csv  \n",
            "  inflating: /content/StateReadMe.pdf  \n",
            "  inflating: /content/database.sqlite  \n",
            "  inflating: /content/hashes.txt     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "n8VQ3YxRgOZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "0FN8jnZ1en_a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into training and test set"
      ],
      "metadata": {
        "id": "G9wE3mt5BeFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 128000\n",
        "split = 0.8\n",
        "\n",
        "data = pd.read_csv('/content/NationalNames.csv')\n",
        "data = data['Name'].apply(lambda n: n.lower()).head(N).sample(frac=1).to_list()\n",
        "\n",
        "i = int(split * N)\n",
        "train, test = data[:i], data[i:]\n",
        "\n",
        "print(f'train data: #{len(train)}, {train[:5]}')\n",
        "print(f'test data: #{len(test)}, {test[:5]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSRZt5icfb_-",
        "outputId": "e0fdc497-5b19-4f48-e52a-ca88cfb0b5eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data: #102400, ['evaline', 'harry', 'dana', 'adda', 'jimmie']\n",
            "test data: #25600, ['livingston', 'delilah', 'charls', 'jean', 'william']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "chars = '.' + string.ascii_lowercase\n",
        "itos = { i:s for i, s in enumerate(chars)}\n",
        "stoi = { s:i for i, s in enumerate(chars)}"
      ],
      "metadata": {
        "id": "kfL7k0H2kHXa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode n-grams**.\n",
        "\n",
        "`context` variable defines the length of the character n-grams (excluding the target character). For example, context = 1 refers to a bigram model.\n",
        "\n",
        "Encoding example:  \n",
        "1. Given the trigram `'ale'`, split it into x and y i.e. `'al'` and `'e'`.  \n",
        "2. Transform the letters into indices i.e. `(1, 12)`, `(5)`.  \n",
        "3. the x indices are then being one-hot encoded and finally\n",
        " concatenated"
      ],
      "metadata": {
        "id": "f7FPMwmOBpzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = 2\n",
        "\n",
        "def encode(data):\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  for w in data:\n",
        "    w = context * '.' + w + '.'\n",
        "\n",
        "    for i in range(len(w) - context):\n",
        "        X_entry = tuple(stoi[w[j]] for j in range(i, i + context))\n",
        "\n",
        "        X.append(X_entry)\n",
        "        Y.append(stoi[w[i + context]])\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Xenc = F.one_hot(X, num_classes=len(chars)).reshape(X.size(0), -1).float()\n",
        "  Y = torch.tensor(Y)\n",
        "  return (Xenc, Y)\n",
        "\n",
        "Xenc, Y = encode(train)\n",
        "XTenc, YT = encode(test)\n",
        "\n",
        "Xenc.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4MIV45Ikt50",
        "outputId": "313926cf-8689-4484-98e6-0cbf4a0c449a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([700053, 54]), torch.Size([700053]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize parameters with random values"
      ],
      "metadata": {
        "id": "62CnKTuqB5_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.rand(Xenc.size(1), len(chars), requires_grad=True)"
      ],
      "metadata": {
        "id": "1S0hN8Jqnr0J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model with a simple neural network without any hidden layers"
      ],
      "metadata": {
        "id": "gy54_7mSB_co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(121):\n",
        "  # forward pass\n",
        "  Yout = Xenc @ W\n",
        "  loss = F.cross_entropy(Yout, Y)\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "  W.data += -10 * W.grad\n",
        "\n",
        "  if i % 30 == 0:\n",
        "    YTout = XTenc @ W\n",
        "    test_loss = F.cross_entropy(YTout, YT)\n",
        "\n",
        "    print('%04d, test loss: %.4f; train loss: %.4f; loss diff: %.4f' % (i, test_loss.item(), loss.item(), abs(loss.item() - test_loss.item())))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX-h3GwIq4SS",
        "outputId": "7434e5a6-1473-419d-f50f-5adbdb2f8979"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000, test loss: 3.2098; train loss: 3.3313; loss diff: 0.1215\n",
            "0030, test loss: 2.4577; train loss: 2.4613; loss diff: 0.0036\n",
            "0060, test loss: 2.3608; train loss: 2.3596; loss diff: 0.0012\n",
            "0090, test loss: 2.3205; train loss: 2.3180; loss diff: 0.0024\n",
            "0120, test loss: 2.2978; train loss: 2.2948; loss diff: 0.0030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = torch.nn.Softmax(dim = 0)\n",
        "\n",
        "def sample(idxs):\n",
        "  x = torch.cat([F.one_hot(torch.tensor(idx), num_classes=len(chars)) for idx in idxs]).float()\n",
        "\n",
        "  return torch.multinomial(softmax(x @ W), num_samples=1, replacement=True).item()"
      ],
      "metadata": {
        "id": "VY_20CClxgNf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate some names"
      ],
      "metadata": {
        "id": "UmofPPkEFW1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  name = ''\n",
        "  idxs = [0] * context\n",
        "\n",
        "  while True:\n",
        "\n",
        "    idxn = sample(idxs)\n",
        "    idxs = idxs[1:] + [idxn]\n",
        "\n",
        "    name += itos[idxn]\n",
        "\n",
        "    if idxn == 0:\n",
        "      break\n",
        "\n",
        "  print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHk-Ady40Ox1",
        "outputId": "ae53ea41-1b37-4b0c-bbae-ae707b0111d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hcr.\n",
            "selle.\n",
            "duorelert.\n",
            "qmathiw.\n",
            "samina.\n",
            "tov.\n",
            "la.\n",
            "ben.\n",
            "juckiy.\n",
            "phna.\n",
            "frtsttestharlbyqrie.\n",
            "dealie.\n",
            "be.\n",
            "nol.\n",
            "he.\n",
            "ca.\n",
            "uzbeqhuoriett.\n",
            "hanate.\n",
            "celerlda.\n",
            "lalqvjdsane.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results\n",
        "\n",
        "**D1:**\n",
        "N = 64000, split = 0.8, context = 5, 5 \\* 27 \\* 27 = 3645 parameters;   \n",
        "1000 iterations, learning rate = 10, loss = 2.0326   \n",
        "took about 4mins to learn on free colab cpu\n",
        "\n",
        "**D2:**\n",
        "N = 128000, split = 0.8, context = 6, 6 \\* 27 \\* 27 = 4374 parameters;   \n",
        "3000 iterations, learning rate = 10, loss = 2.1324   \n",
        "took about 33mins to learn on free colab cpu\n",
        "\n",
        "| D1 | D2 |\n",
        "| - | - |\n",
        "| marcie. | kil. |\n",
        "| aus. | vilanna. |\n",
        "| cilma. | vilana. |\n",
        "| micos. | lanoros. |\n",
        "| cly. | alla. |\n",
        "| jolmetha. | wilman. |\n",
        "| elborie. | elvardett. |\n",
        "| rina. | lanay. |\n",
        "| garoge. | arlie. |\n",
        "| thaldpery. | olly. |\n",
        "| bethia. | lichaok. |\n",
        "| cencisel. | livarga. |\n",
        "| euda. | panallisa. |\n",
        "| wandeca. | arillda. |\n",
        "| nandy. | kalluen. |\n",
        "| vwanner. | anfaid. |\n",
        "| sapvin. | jonnita. |\n",
        "| wirndf. | byha. |\n",
        "| bone. | alina. |\n",
        "| sernjel. | badsilit. |"
      ],
      "metadata": {
        "id": "ZSvTPzcVHGgF"
      }
    }
  ]
}